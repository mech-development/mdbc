{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unicode Handling\n",
    "from __future__ import unicode_literals\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# spacy is used for pre-processing and traditional NLP\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Model 'en>=1.1.0,<1.2.0' not installed. Please run 'python -m spacy.en.download' to install latest compatible model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ee13015793fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Setting up spacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnlp_toolkit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mactzu/anaconda2/lib/python2.7/site-packages/spacy/language.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, vocab, tokenizer, tagger, parser, entity, matcher, serializer, load_vectors, package, vectors_package)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpackage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mpackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_package_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__models__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mpackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mactzu/anaconda2/lib/python2.7/site-packages/spacy/util.pyc\u001b[0m in \u001b[0;36mget_package_by_name\u001b[0;34m(name, via)\u001b[0m\n\u001b[1;32m     46\u001b[0m         raise RuntimeError(\"Model '%s' not installed. Please run 'python -m \"\n\u001b[1;32m     47\u001b[0m                            \u001b[0;34m\"%s.download' to install latest compatible \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                            \"model.\" % (name, lang.__module__))\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mCompatiblePackageNotFoundException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         raise RuntimeError(\"Installed model is not compatible with spaCy \"\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Model 'en>=1.1.0,<1.2.0' not installed. Please run 'python -m spacy.en.download' to install latest compatible model."
     ]
    }
   ],
   "source": [
    "# Loading the tweet data\n",
    "filename = \"../../../../data/captured-tweets.txt\"\n",
    "tweets = []\n",
    "for tweet in codecs.open(filename, \"r\", encoding = \"utf-8\"):\n",
    "    tweets.append(tweet)\n",
    "# Setting up spacy\n",
    "nlp_toolkit = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1a\n",
    "Write a function that can take a sentence parsed by `spacy` and identify if it mentions a company named \"Google\". Remember, `spacy` can find entities and codes them as `ORG` if they are a company. Look at the slides for class 13 if you need a hint:\n",
    "\n",
    "### Bonus (1b)\n",
    "Parameterise the company name so that the function works for any company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1a\n",
    "def mentions_company(parsed):\n",
    "    # Return True if the sentence contains an organization and that organization is Google\n",
    "    for entity in parsed.ents:\n",
    "        pass # remove this line\n",
    "        # <Code Here>\n",
    "    # Otherwise return False\n",
    "    return False\n",
    "\n",
    "# 1b\n",
    "def mentions_company(parsed, company = \"Google\"):\n",
    "    pass # remove this line\n",
    "    # <Code Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1c\n",
    "Write a function that can take a sentence parsed by `spacy` and return the verbs of the sentence (preferably lemmatised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_actions(parsed):\n",
    "    actions = []\n",
    "    # <Code Here>\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1d\n",
    "For each tweet, parse it using spacy and print it out if the tweet has \"release\" or \"announce\" as a verb. You will need to use your `mentions_company` and `get_actions` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    # <Code Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 1e\n",
    "Write a function that identifies countries - HINT: the entity label for countries is GPE (or GeoPolitical Entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_country(parsed, country):\n",
    "    pass # remove this line\n",
    "    # <Code Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1f\n",
    "Re-run (d) to find country tweets that discuss \"Iran\" announcing or releasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    # <Code Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "- Build a word2vec model of the tweets we have collected using `gensim`.\n",
    "- First take the collection of tweets and tokenise them using `spacy`.\n",
    "\n",
    "### Exercise 2a\n",
    "- Think about how this should be done. \n",
    "- Should you only use upper-case or lower-case? \n",
    "- Should you remove punctuations or symbols? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_split = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                for x in nlp_toolkit(t)] for t in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b\n",
    "- Build a word2vec model\n",
    "- Test the window size as well - this is how many surrounding words need to be used to model a word. What do you think is appropriate for Twitter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text_split, size = 100, window = 4, min_count = 5, workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2c\n",
    "Test your word2vec model with a few similarity functions\n",
    "- Find words similar to \"Syria\"\n",
    "- Find words similar to \"war\"\n",
    "- Find words similar to \"Iran\"\n",
    "- Find words similar to \"Verizon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive = [\"Syria\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2d\n",
    "Adjust the choices in (b) and (c) as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Filter tweets to those that mention \"Iran\" or similar entities and \"war\" or similar entities\n",
    "- Do this using just spacy\n",
    "- Do this using word2vec similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using spacy\n",
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    # <Code Here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using word2vec similarity scores\n",
    "for tweet in tweets[:200]:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    # <Code Here>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
