{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6 - Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the mammal dataset\n",
    "wd = \"../../../../data/\"\n",
    "mammals = pd.read_csv(wd + \"msleep.csv\")\n",
    "mammals = mammals[mammals.brainwt.notnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore our mammals data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mammals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets check out a scatter plot of body weight and brain weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a matplotlib figure\n",
    "plt.figure()\n",
    "# generate a scatterplot inside the figure\n",
    "plt.plot(mammals.bodywt, mammals.brainwt, \".\")\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(\"bodywt\", \"brainwt\", mammals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_columns = [\"bodywt\", \"brainwt\", ]\n",
    "log_mammals = mammals.copy()\n",
    "log_mammals[log_columns] = log_mammals[log_columns].apply(np.log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(\"bodywt\", \"brainwt\", log_mammals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Practice: Using Seaborn to generate single variable linear model plots (15 mins)\n",
    "Update and complete the code below to use `lmplot` and display correlations between `body weight` and two dependent variables: `sleep_rem` and `awake`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_columns = [\"bodywt\", \"brainwt\", ] # any others?\n",
    "log_mammals = mammals.copy()\n",
    "log_mammals[log_columns] = log_mammals[log_columns].apply(np.log10)\n",
    "\n",
    "# <Code Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete below for `sleep_rem` and `awake` as a y, with variables you have already used as x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x, y, mammals)\n",
    "sns.lmplot(x, y, log_mammals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_columns = [\"bodywt\", \"brainwt\", \"awake\", \"sleep_rem\"] # any others?\n",
    "log_mammals = mammals.copy()\n",
    "log_mammals[log_columns] = log_mammals[log_columns].apply(np.log10)\n",
    "\n",
    "# one other example, using brainwt and awake.\n",
    "x = \"brainwt\"\n",
    "y = \"awake\"\n",
    "sns.lmplot(x, y, mammals)\n",
    "sns.lmplot(x, y, log_mammals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Single Regression Analysis in statsmodels and scikit (10 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is the standard import if you are using \"formula notation\" (similar to R)\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "X = mammals[[\"bodywt\"]]\n",
    "y = mammals[\"brainwt\"]\n",
    "\n",
    "# create a fitted model in one line\n",
    "# formula notiation is the equivalent to writting out our models such that \"outcome = predictor\"\n",
    "# with the follwing syntax formula = \"outcome ~ predictor1 + predictor2 ... predictorN\"\n",
    "lm = smf.ols(formula = \"y ~ X\", data = mammals).fit()\n",
    "\n",
    "# print the full summary\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use Statsmodels to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you have to create a DataFrame since the Statsmodels formula interface expects it\n",
    "X_new = pd.DataFrame({\"X\": [50]})\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat in Scikit with handy plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modeling with sklearn, you will use the following base principals.\n",
    "\n",
    "- All sklearn estimators (modeling classes) are based on this base estimator. This allows you to easily rotate through estimators without changing much code.\n",
    "- All estimators take a matrix, X, either sparse or dense.\n",
    "- Many estimators also take a vector, y, when working on a supervised machine learning problem. Regressions are supervised learning because we already have examples of y given X.\n",
    "- All estimators have parameters that can be set. This allows for customization and higher level of detail to the learning process. The parameters are appropriate to each estimator algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_selection, linear_model\n",
    "\n",
    "def get_linear_model_metrics(X, y, algo):\n",
    "    # get the pvalue of X given y. Ignore f-stat for now.\n",
    "    pvals = feature_selection.f_regression(X, y)[1]\n",
    "    # start with an empty linear regression object\n",
    "    # .fit() runs the linear regression function on X and y\n",
    "    algo.fit(X, y)\n",
    "    residuals = (y - algo.predict(X)).values\n",
    "\n",
    "    # print the necessary values\n",
    "    print \"P Values    :\", pvals\n",
    "    print \"Coefficients:\", algo.coef_\n",
    "    print \"y-intercept :\", algo.intercept_\n",
    "    print \"R-Squared   :\", algo.score(X,y)\n",
    "    plt.figure()\n",
    "    plt.hist(residuals, bins = int(np.ceil(np.sqrt(len(y)))))\n",
    "    # keep the model\n",
    "    return algo\n",
    "\n",
    "X = mammals[[\"bodywt\"]]\n",
    "y = mammals[\"brainwt\"]\n",
    "lm = linear_model.LinearRegression()\n",
    "lm = get_linear_model_metrics(X, y, lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration: Significance is Key (20 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does our output tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output tells us that:\n",
    "\n",
    "- The relationship between bodywt and brainwt is not random (p-value approaching 0)\n",
    "- The model explains, roughly, 87% of the variance of the data set (the largest errors being in the large brain and body sizes)\n",
    "- With this current model, brainwt is roughly `bodywt * 0.00096395`\n",
    "- The residuals, or error in the prediction, is not normal, with outliers on the right. A better with will have similar to normally distributed error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Fit, Evaluating Sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we know there is a better solution to the model, we should evaluate some other sense things first. For example, given this model, what is an animal's brainwt if their bodywt is 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction at 0?\n",
    "print lm.predict([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression(fit_intercept = False)\n",
    "lm = get_linear_model_metrics(X, y, lm)\n",
    "# prediction at 0?\n",
    "print lm.predict([[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrepretation?\n",
    "Answer: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Practice: Using the LinearRegression object (15 mins)\n",
    "\n",
    "We learned earlier that the the data in its current state does not allow for the best linear regression fit.\n",
    "\n",
    "With a partner, generate two more models using the log-transformed data to see how this transform changes the model's performance.\n",
    "\n",
    "Complete the following code to update X and y to match the log-transformed data.\n",
    "\n",
    "Complete the loop by setting the list to be one True and one False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# starter\n",
    "X =\n",
    "y =\n",
    "loop = []\n",
    "for boolean in loop:\n",
    "    print \"y-intercept:\", boolean\n",
    "    lm = linear_model.LinearRegression(fit_intercept = boolean)\n",
    "    get_linear_model_metrics(X, y, lm)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "X = log_mammals[[\"bodywt\"]]\n",
    "y = log_mammals[\"brainwt\"]\n",
    "loop = [True, False]\n",
    "for boolean in loop:\n",
    "    print \"y-intercept:\", boolean\n",
    "    lm = linear_model.LinearRegression(fit_intercept = boolean)\n",
    "    get_linear_model_metrics(X, y, lm)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: Which model performed the best? The worst? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Methods!\n",
    "We will go over different estimators in detail in the future but check it out in the docs if you are curious..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading other sklearn regression estimators\n",
    "X = log_mammals[[\"bodywt\"]]\n",
    "y = log_mammals[\"brainwt\"]\n",
    "\n",
    "estimators = [\n",
    "    linear_model.Lasso(),\n",
    "    linear_model.Ridge(),\n",
    "    linear_model.ElasticNet(),\n",
    "]\n",
    "\n",
    "for est in estimators:\n",
    "    print est\n",
    "    get_linear_model_metrics(X, y, est)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Multiple Regression Analysis using citi bike data (10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, one variable explained the variance of another; however, more often than not, we will need multiple variables.\n",
    "\n",
    "For example, a house's price may be best measured by square feet, but a lot of other variables play a vital role: bedrooms, bathrooms, location, appliances, etc.\n",
    "\n",
    "For a linear regression, we want these variables to be largely independent of each other, but all of them should help explain the y variable.\n",
    "\n",
    "We will work with bikeshare data to showcase what this means and to explain a concept called multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wd = \"../../../../data/\"\n",
    "bike_data = pd.read_csv(wd + \"bikeshare.csv\")\n",
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Multicollinearity?\n",
    "\n",
    "With the bike share data, let's compare three data points: actual temperature, \"feel\" temperature and guest ridership.\n",
    "\n",
    "Our data is already normalized between 0 and 1, so we will start off with the correlations and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "\n",
    "correlations = bike_data[[\"temp\", \"atemp\", \"casual\"]].corr()\n",
    "print correlations\n",
    "print sns.heatmap(correlations, cmap = cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the correlation matrix explain?\n",
    "\n",
    "Answer: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can measure this effect in the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = bike_data[\"casual\"]\n",
    "x_sets = (\n",
    "    [\"temp\"],\n",
    "    [\"atemp\"],\n",
    "    [\"temp\", \"atemp\"],\n",
    ")\n",
    "\n",
    "for x in x_sets:\n",
    "    print \", \".join(x)\n",
    "    get_linear_model_metrics(bike_data[x], y, linear_model.LinearRegression())\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Intrepretation:\n",
    "\n",
    "Answer: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if we use a second variable that is not highly correlated with temperature, like humidity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = bike_data[\"casual\"]\n",
    "x = bike_data[[\"temp\", \"hum\"]]\n",
    "get_linear_model_metrics(x, y, linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Practice: Multicollinearity with dummy variables (15 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be a similar effect from a feature set that is a singular matrix, which is when there is a clear relationship in the matrix (for example, the sum of all rows = 1).\n",
    "\n",
    "### Run through the following code on your own.\n",
    "#### What happens to the coefficients when you include all weather situations instead of just including all except one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "weather = pd.get_dummies(bike_data.weathersit)\n",
    "\n",
    "get_linear_model_metrics(weather[[1, 2, 3, 4]], y, lm)\n",
    "print\n",
    "# drop the least significant, weather situation = 4\n",
    "get_linear_model_metrics(weather[[1, 2, 3]], y, lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all dummies in the model\n",
    "lm_stats = smf.ols(formula = \"y ~ weather[[1, 2, 3, 4]]\", data = bike_data).fit()\n",
    "lm_stats.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# droping one\n",
    "lm_stats = smf.ols(formula = \"y ~ weather[[1, 2, 3]]\", data = bike_data).fit()\n",
    "lm_stats.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the interpretation ? Do you want to keep all your dummy variables or drop one? Why?\n",
    "\n",
    "Answer: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Practice: Combining non-correlated features into a better model (15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a partner, complete this code together and visualize the correlations of all the numerical features built into the data set.\n",
    "\n",
    "We want to:\n",
    "\n",
    "- Add the three significant weather situations into our current model\n",
    "- Find two more features that are not correlated with current features, but could be strong indicators for predicting guest riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# starter\n",
    "lm = linear_model.LinearRegression()\n",
    "bikemodel_data = bike_data.join() # add in the three weather situations\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "correlations = # <Code Here> # what are we getting the correlations of?\n",
    "print correlations\n",
    "print sns.heatmap(correlations, cmap = cmap)\n",
    "\n",
    "columns_to_keep = [] # [which_variables?]\n",
    "final_feature_set = bikemodel_data[columns_to_keep]\n",
    "\n",
    "get_linear_model_metrics(final_feature_set, y, lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "final_feature_set = bikemodel_data[columns_to_keep]\n",
    "get_linear_model_metrics(final_feature_set, np.log10(y + 1), lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stats models\n",
    "log_y = np.log10(y + 1)\n",
    "lm = smf.ols(formula = \"log_y ~ temp + hum + windspeed + weather_1 + weather_2 + weather_3 + holiday + hour_1 + hour_2 + hour_3 + hour_4 + hour_5 + hour_6 + hour_7 + hour_8 + hour_9 + hour_10 + hour_11 + hour_12 + hour_13 + hour_14 + hour_15 + hour_16 + hour_18 + hour_19 + hour_20 + hour_21 + hour_22 + hour_23\",\n",
    "             data = bikemodel_data).fit()\n",
    "# print the full summary\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "lm = linear_model.LinearRegression()\n",
    "weather = pd.get_dummies(bike_data.weathersit)\n",
    "weather.columns = [\"weather_\" + str(i) for i in weather.columns]\n",
    "\n",
    "hours = pd.get_dummies(bike_data.hr)\n",
    "hours.columns = [\"hour_\" + str(i) for i in hours.columns]\n",
    "\n",
    "season = pd.get_dummies(bike_data.season)\n",
    "season.columns = [\"season_\" + str(i) for i in season.columns]\n",
    "\n",
    "bikemodel_data = bike_data.join(weather) # add in the three weather situations\n",
    "bikemodel_data = bikemodel_data.join(hours)\n",
    "bikemodel_data = bikemodel_data.join(season)\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "\n",
    "columns_to_keep = [\"temp\", \"hum\",\n",
    "                   \"windspeed\", \"weather_1\", \"weather_2\", \"weather_3\",\n",
    "                   \"holiday\", ]\n",
    "columns_to_keep.extend([\"hour_\" + str(i) for i in range(1, 24)])\n",
    "\n",
    "correlations = bikemodel_data[columns_to_keep].corr()\n",
    "print correlations\n",
    "print sns.heatmap(correlations, cmap = cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Practice: Building models for other y variables (25 minutes)\n",
    "\n",
    "We have completely a model together that explains casual guest riders. Now it is your turn to build another model, using a different y variable: registered riders.\n",
    "\n",
    "### Pay attention to:\n",
    "\n",
    "- the distribution of riders (should we rescale the data?)\n",
    "- checking correlations with variables and registered riders\n",
    "- having a feature space (our matrix) with low multicollinearity\n",
    "- model complexity vs explanation of variance: at what point do features in a model stop improving r-squared?\n",
    "- the linear assumption -- given all feature values being 0, should we have no ridership? negative ridership? positive ridership?\n",
    "\n",
    "### Bonus\n",
    "\n",
    "- Which variables would make sense to dummy (because they are categorical, not continuous)?\n",
    "- What features might explain ridership but are not included in the data set?\n",
    "- Is there a way to build these using pandas and the features available?\n",
    "- Outcomes: If your model at least improves upon the original model and the explanatory effects (coefficients) make sense, consider this a complete task.\n",
    "\n",
    "### If your model has an r-squared above 0.4, this a relatively effective model for the data available. Kudos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# <Code Here>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
