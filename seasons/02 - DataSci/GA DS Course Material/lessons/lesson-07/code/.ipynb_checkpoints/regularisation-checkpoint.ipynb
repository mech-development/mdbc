{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following function of the \"ground truth\" and a few sample data points we will use for regression.\n",
    "\n",
    "The example is by Mathieu Blondel & Jake Vanderplas ([source](http://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = lambda x: x * np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, n = 1000, 10\n",
    "domain = np.linspace(0, 10, N)\n",
    "x_sample = np.sort(np.random.choice(domain, n))\n",
    "y_sample = func(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(domain[:5])\n",
    "print(domain[995:])\n",
    "print(x_sample.shape)\n",
    "print(y_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.plot(domain, func(domain), label = \"ground truth\")\n",
    "f = plt.scatter(x_sample, func(x_sample), label = \"samples\")\n",
    "f = plt.legend(loc = \"upper left\", bbox_to_anchor = (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously linear regression will not bring you far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([x_sample]).T\n",
    "model = LinearRegression().fit(X, y_sample)\n",
    "print(\"R2 = %f\" % model.score(X, y_sample))\n",
    "f = plt.plot(domain, func(domain), label = \"ground truth\")\n",
    "f = plt.scatter(x_sample, func(x_sample), label = \"samples\")\n",
    "f = plt.plot([0, 10], [model.intercept_, model.intercept_ + 10 * model.coef_[0]], label = \"linear regression\")\n",
    "f = plt.legend(loc = \"upper left\", bbox_to_anchor = (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a few polynomial regressions to fit the given sample data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([x_sample]).T\n",
    "# f = plt.plot(x, func(x), label = \"ground truth\", alpha = 0.4)\n",
    "f = plt.scatter(x_sample, func(x_sample), label = \"samples\")\n",
    "\n",
    "degree = 4\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression()).fit(X, y_sample)\n",
    "y_pred = model.predict(np.array([domain]).T)\n",
    "plt.plot(domain, y_pred, label = \"degree %d\" % degree)\n",
    "\n",
    "f = plt.legend(loc = \"upper left\", bbox_to_anchor = (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is actually a result from algebra that you can fit **any** finite set of data points with a polynomial.\n",
    "- In fact, for any set of $n$ data points, there exists a polynomial of degree $n$ that goes right through them.\n",
    "- This is great if you would want to approximate your data arbitrarily closely.\n",
    "- It is not great if you are afraid of overfitting your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to find a model behind some data, which also contains some arbitrary noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = lambda x: 1 + 0.1 * (x - 4) ** 2 + 4 * np.random.random(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, n = 1000, 30\n",
    "domain = np.linspace(0, 15, N)\n",
    "x_sample = np.linspace(0, 15, n)\n",
    "y_sample = func(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.scatter(x_sample, func(x_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously you could fit this noise by an arbitrarily complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([x_sample]).T\n",
    "f = plt.scatter(x_sample, func(x_sample))\n",
    "\n",
    "for degree in [3, 8, 13]:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression()).fit(X, y_sample)\n",
    "    y_pred = model.predict(np.array([domain]).T)\n",
    "    plt.plot(domain, y_pred, alpha = 0.5, label = \"deg %d (R2 %.2f)\" % (degree, model.score(X, y_sample)))\n",
    "\n",
    "f = plt.legend(loc = \"upper left\", bbox_to_anchor = (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that is obviously not what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.scatter(x_sample, func(x_sample), label = \"samples\")\n",
    "for degree in [1, 2, 3, 4, 5]:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    # Compute a few R2 scores and print average performance\n",
    "    scores = []\n",
    "    for k in xrange(15):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_sample, train_size = 0.7)\n",
    "        scores.append(model.fit(X_train, y_train).score(X_test, y_test))\n",
    "    print(\"For degree %d, R^2 = %f\" % (degree, np.mean(scores)))\n",
    "    # Take last model to plot predictions\n",
    "    y_pred = model.predict(np.array([domain]).T)\n",
    "    plt.plot(domain, y_pred, alpha = 0.5, label = \"deg %d ($R^2$ %.2f)\" % (degree, model.score(X_test, y_test)))\n",
    "\n",
    "    f = plt.legend(loc = \"upper left\", bbox_to_anchor = (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a second or third degree polynomial performs better than a fifth one on unseen data, which makes sense, since that is how we generated the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the different models once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_performance(test_model):\n",
    "    scores = {\"overfit\": {}, \"cv\": {}}\n",
    "    for degree in xrange(0, 30):\n",
    "        model = make_pipeline(PolynomialFeatures(degree), test_model)\n",
    "        scores[\"overfit\"][degree] = model.fit(X, y_sample).score(X, y_sample)\n",
    "        cv_scores = []\n",
    "        for k in xrange(15): # Compute a few R2 scores and print average performance\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y_sample, train_size = 0.7)\n",
    "            cv_scores.append(model.fit(X_train, y_train).score(X_test, y_test))\n",
    "        scores[\"cv\"][degree] = np.mean(cv_scores)\n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = analyze_performance(LinearRegression())\n",
    "f = scores.plot(ylim = (-0.05, 1.05))\n",
    "f = plt.title(\"Best cv performance at degree %d\" % scores.cv.argmax()), plt.xlabel(\"degree\"), plt.ylabel(\"$R^2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "If your model is very complex (i.e., lots of features, possibly a polynomial fit, etc.), you need to worry more about overfitting.\n",
    "- You will need regularization when your model is complex, which happens when you have little data or many features\n",
    "- The example below uses the same data set as above, but with fewer samples and a relatively high degree model\n",
    "- We will fit the (unregularized) `LinearRegression`, as well as the (regularized) `Ridge` and `Lasso` model\n",
    "  - Lasso regression imposes an L1 prior on the coefficient, causing many coeffiecients to be zero\n",
    "  - Ridge regression imposes an L2 prior on the coefficient, causing outliers to be less likely, and coeffiecients to be small across the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_small_sample = x_sample[::4]\n",
    "y_small_sample = func(x_small_sample)\n",
    "\n",
    "degree, alpha = 4, 10\n",
    "\n",
    "XX = np.array([x_small_sample]).T\n",
    "fig, axes = plt.subplots(1, 3, figsize = (20, 4))\n",
    "for no, my_model in enumerate([LinearRegression(), Ridge(alpha = alpha), Lasso(alpha = alpha)]):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), my_model)\n",
    "    r2, MSE = [], []\n",
    "    for k in xrange(100): # Fit a few times the model to different training sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(XX, y_small_sample, train_size = 0.7)\n",
    "        r2.append(model.fit(X_train, y_train).score(X_test, y_test))\n",
    "        y_pred = model.predict(np.array([domain]).T)\n",
    "        axes[no].plot(domain, y_pred, alpha = 0.3)\n",
    "        y_pred_sample = model.predict(np.array([x_small_sample]).T)\n",
    "        MSE.append(np.square(y_pred_sample - y_small_sample).sum())\n",
    "    axes[no].scatter(x_small_sample, y_small_sample, s = 70)\n",
    "    #axes[no].set_title(\"%s (R2 %.2f, MSE %3f)\" % (my_model.__class__.__name__, np.mean(scores), np.mean(MSE)))\n",
    "    axes[no].set_title(\"%s ($R^2$ %.2f, MSE %3f)\" % (my_model.__class__.__name__, np.mean(r2), np.mean(MSE)))\n",
    "    axes[no].set_xlim(-0.2, max(domain)), axes[no].set_ylim(-1, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Indeed, the unregularized `LinearRegression` leads to a model that is too complex and tries to fit the noise\n",
    "- Note the differences in the (averaged) mean square error, or MSE, as well the complexity in the plots\n",
    "- Note that the $R^2$ metric is not helpful here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few degrees with a regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_models = [LinearRegression(), Ridge(alpha = 10), Lasso(alpha = 10)]\n",
    "\n",
    "scores = [analyze_performance(my_model) for my_model in test_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize = (20, 4))\n",
    "for no, score in enumerate(scores):\n",
    "    s, name = pd.DataFrame(score), test_models[no].__class__.__name__\n",
    "    f = s.plot(ylim = (-0.05, 1.05), ax = axes[no], legend = False)\n",
    "    f = axes[no].set_title(\"%s\\nBest cv performance at degree %d\" % (name, s.cv.argmax()))\n",
    "    f = axes[no].set_xlabel(\"degree\"), axes[no].set_ylabel(\"$R^2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try a few different values for $\\alpha$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize = (18, 6))\n",
    "for col, alpha in enumerate([0, 1, 10, 100]):\n",
    "    scores = [analyze_performance(my_model) for my_model in [Ridge(alpha = alpha), Lasso(alpha = alpha)]]\n",
    "    for row, score in enumerate(scores):\n",
    "        s, name = pd.DataFrame(score), test_models[row].__class__.__name__\n",
    "        f = s.plot(ylim = (-0.05,1.05), ax = axes[row, col], legend = False)\n",
    "        f = axes[row, col].set_title(\"%s (alpha %d)\\nBest cv at degree %d\" % (name, alpha, s.cv.argmax()))\n",
    "        f = axes[row, col].set_xlabel(\"degree\"), axes[row, col].set_ylabel(\"$R^2$\")\n",
    "f = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that that Ridge and Lasso keep performing well for higher degrees, because of their regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(Not verified yet.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Take a dataset from the previous Linear Regression notebook (eg Princeton salaries or Boston house prices) and try to repeat the exercises using regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.RidgeCV(alphas = [0.1, 1.0, 10.0])\n",
    "model.fit(X, y)\n",
    "\n",
    "print model.coef_\n",
    "print model.alpha_\n",
    "```\n",
    "\n",
    "### Additional Resources\n",
    "- [Linear Regression with Python](http://connor-johnson.com/2014/02/18/linear-regression-with-python/)\n",
    "- [Statsmodels Documentation](http://statsmodels.sourceforge.net/stable/index.html)\n",
    "- [Python 538 Model](https://github.com/jseabold/538model)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
