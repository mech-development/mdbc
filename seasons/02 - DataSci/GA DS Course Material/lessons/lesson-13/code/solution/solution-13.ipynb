{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 13 - Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"../../../../data/stumbleupon.tsv\", sep = \"\\t\")\n",
    "data[\"title\"] = data.boilerplate.map(lambda x: json.loads(x).get(\"title\", \"\"))\n",
    "data[\"body\"] = data.boilerplate.map(lambda x: json.loads(x).get(\"body\", \"\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \"Greenness\" of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender\n",
    "\n",
    "A description of the columns is below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at [www.alchemyapi.com](www.alchemyapi.com))\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at [www.alchemyapi.com](www.alchemyapi.com))\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of embed usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an `<a>` with an url with domain\n",
    "html_ratio|double|Ratio of `<html>` tags vs text in the page\n",
    "image_ratio|double|Ratio of `<img>` tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 `<a>`'s text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrised if it is url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try extracting some of the text content\n",
    "Create a feature for the title containing \"recipe\". Is the % of evegreen websites higher or lower on pages that have recipe in the the title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option 1: Create a function to check for this\n",
    "def has_recipe(text_in):\n",
    "    try:\n",
    "        if \"recipe\" in str(text_in).lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except: \n",
    "        return 0\n",
    "        \n",
    "data[\"recipe\"] = data[\"title\"].map(has_recipe)\n",
    "\n",
    "# Option 2: lambda functions\n",
    "# data[\"recipe\"] = data[\"title\"].map(lambda t: 1 if \"recipe\" in str(t).lower() else 0)\n",
    "\n",
    "# Option 3: string functions\n",
    "# data[\"recipe\"] = data[\"title\"].str.contains(\"recipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration: Use of the Count Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = data[\"title\"].fillna(\"\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectoriser = CountVectorizer(max_features = 1000,\n",
    "                             ngram_range  = (1, 2),\n",
    "                             stop_words   = \"english\",\n",
    "                             binary       = True)\n",
    "\n",
    "# Use `fit` to learn the vocabulary of the titles\n",
    "vectoriser.fit(titles)\n",
    "\n",
    "# Use `transform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectoriser.transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration: Build a random forest model to predict evergreeness of a website using the title features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 20)\n",
    "\n",
    "# Use `fit` to learn the vocabulary of the titles\n",
    "vectoriser.fit(titles)\n",
    "\n",
    "# Use `transform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectoriser.transform(titles).toarray()\n",
    "y = data[\"label\"]\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring = \"roc_auc\")\n",
    "print(\"CV AUC {}, Average AUC {}\".format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Build a random forest model to predict evergreeness of a website using the title features and quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use `transform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X_text_features = vectoriser.transform(titles)\n",
    "\n",
    "# Identify the features you want from the original data set\n",
    "other_features_columns = [\"html_ratio\", \"image_ratio\"]\n",
    "other_features = data[other_features_columns]\n",
    "\n",
    "# Stack them horizontally together\n",
    "# This takes all of the word/n-gram columns and appends on two more columns for `html_ratio` and `image_ratio`\n",
    "from scipy.sparse import hstack\n",
    "X = hstack((X_text_features, other_features)).toarray()\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring = \"roc_auc\")\n",
    "print(\"CV AUC {}, Average AUC {}\".format(scores, scores.mean()))\n",
    "\n",
    "# What features of these are most important?\n",
    "model.fit(X, y)\n",
    "\n",
    "all_feature_names = vectoriser.get_feature_names() + other_features_columns\n",
    "feature_importances = pd.DataFrame({\"Features\" : all_feature_names, \"Importance Score\": model.feature_importances_})\n",
    "feature_importances.sort_values(\"Importance Score\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Build a random forest model to predict evergreeness of a website using the body features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "body_text = data[\"body\"].fillna(\"\")\n",
    "\n",
    "# Use `fit` to learn the vocabulary\n",
    "vectoriser.fit(body_text)\n",
    "\n",
    "# Use `transform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectoriser.transform(body_text).toarray()\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring = \"roc_auc\")\n",
    "print(\"CV AUC {}, Average AUC {}\".format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Use `TfIdfVectorizer` instead of `CountVectorizer` - is this an improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = data[\"title\"].fillna(\"\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectoriser = TfidfVectorizer(max_features = 1000,\n",
    "                             ngram_range  = (1, 2),\n",
    "                             stop_words   = \"english\")\n",
    "\n",
    "# Use `fit` to learn the vocabulary\n",
    "vectoriser.fit(body_text)\n",
    "\n",
    "# Use `transform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "X = vectoriser.transform(body_text).toarray()\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring = \"roc_auc\")\n",
    "print(\"CV AUC {}, Average AUC {}\".format(scores, scores.mean()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ga]",
   "language": "python",
   "name": "conda-env-ga-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
